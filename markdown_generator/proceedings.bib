@inproceedings{IS2014_asha,
      title = {Feature Switching in the i-vector Framework for Speaker  Verification},
      author = {T, Asha and Saranya M. S. and Karthik Pandia D. S. and  Madikeri, Srikanth and Murthy, Hema A.},
      year = {2014},
      booktitle = {15th Annual Conference of the International Speech Communication Association},
      publisher = {ISCA},
      pages = {1125-1129},
      url = {https://www.isca-speech.org/archive/interspeech_2014/i14_1125.html},
      abstract = {Feature fusion is a paradigm that has found success in a number of speech related tasks. The primary objective in applying fusion is to leverage the complementary information present in the features. Conventionally, either early or late fusion is employed. Early fusion leads to large dimensional feature vectors. Further, the range of feature values for different streams require appropriate normalisation. Late fusion is carried out at score level, where the contribution from each type of feature is determined from the set of weights used. Feature switching is yet another paradigm that attempts to capture the diversity in the feature types used. Feature switching gains significance particularly in the context of speaker verification, where the feature type that best discriminates a speaker is used to verify the claims corresponding to that speaker. Earlier, feature switching was attempted in the conventional UBM-GMM framework. In this paper, the idea is extended to the Total Variability Space (TVS) framework. Two different feature types namely Modified Group Delay (MGD) and Mel-Frequency Cepstral Coefficients (MFCC) are explored in the proposed framework. Results are presented on NIST 2010 male database for the speaker verification task.}
}

@INPROCEEDINGS{tenconPaper,
author={V. S. {Solomi} and M. S. {Saranya} and G. A. {Rachel} and P. {Vijayalakshmi} and T. {Nagarajan}},
booktitle={TENCON 2014 - 2014 IEEE Region 10 Conference},
title={Performance comparison of KLD and PoG metrics for finding the acoustic similarity between phonemes for the development of a polyglot synthesizer},
year={2014},
volume={},
number={},
pages={1-4},
keywords={acoustic signal processing;Gaussian processes;hidden Markov models;natural language processing;speech synthesis;PoG metrics;KLD metrics;acoustic similarity;phonemes;text-to-speech synthesis system;multiple language-specific synthesizers;language-switching;Kullback-Leibler-based metrics;product of likelihood-Gaussians based metrics;separate HMM-based polyglot synthesizers;degraded mean-opinion-score;DMOS;language-influence;Synthesizers;Speech;Switches;Hidden Markov models;Measurement;Merging;Polyglot synthesizer;bilingual;KLD;PoG;acoustic similarity},
doi={10.1109/TENCON.2014.7022438},
ISSN={2159-3450},
month={Oct}
}

@INPROCEEDINGS{KWS, 
author={K. P. D. {S} and M. S. {Saranya} and H. A. {Murthy}}, 
booktitle={2016 International Conference on Signal Processing and Communications (SPCOM)}, 
title={A fast query-by-example spoken term detection for zero resource languages}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-5}, 
keywords={query processing;speaker recognition;time warp simulation;score normalization technique;keyword occurrences;segmented audio;syllable boundaries;segmental DTW;query term occurrences;UE-DTW algorithm;unconstrained-endpoint dynamic time warping algorithm;zero resource languages;QbE-STD system;query-by-example spoken term detection system;two-pass DTW approach;two-pass dynamic time warping approach;Speech;Mel frequency cepstral coefficient;Computer science;Electronic mail;Speech recognition;Time factors;Heuristic algorithms}, 
doi={10.1109/SPCOM.2016.7746600}, 
ISSN={}, 
month={June}
}

@INPROCEEDINGS{DLFS_Spcom, 
author={M. S. {Saranya} and R. {Padmanabhan} and H. A. {Murthy}}, 
booktitle={2018 International Conference on Signal Processing and Communications (SPCOM)}, 
title={Replay Attack Detection in Speaker Verification Using non-voiced segments and Decision Level Feature Switching}, 
year={2018}, 
volume={}, 
number={}, 
pages={332-336}, 
keywords={feature extraction;Gaussian processes;mixture models;reverberation;speaker recognition;nonvoiced segments;voice activity detector;reverberation;channel information;replay attack detection;decision level feature switching;speaker verification;utterances;feature representation;vocal tract information;Gaussian mixture models;equal error rate;ASV-Spoof-2017 challenge dataset;Feature extraction;Reverberation;Mel frequency cepstral coefficient;Switches;Mathematical model;Gaussian mixture model}, 
doi={10.1109/SPCOM.2018.8724469}, 
ISSN={2474-915X}, 
month={July}
}

@article{IS2018_saranya,
      title = {Decision-level feature switching as a paradigm for replay attack detection},
      author = {Saranya M. S., Hema A. Murthy},
      year = {2018},
      booktitle = {19th Annual Conference of the International Speech Communication Association},
      publisher = {ISCA},
      pages = {686-690},
      url = {https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1494.pdf},
      abstract = {A pre-recorded audio sample of an authentic speaker presented to a voice-based biometric system is termed as a replay attack. Such attacks can be detected by identifying the characteristics of the recording device and environment. An analysis of different recording devices indicates that each recording device affects the spectrum differently. It is also observed that each feature captures specific characteristics of recording devices. In particular, Mel Filterbank Slope (MFS) captures low-frequency information corresponding to that of the low-quality recording devices, while Linear Filterbank Slope (LFS) captures highfrequency information which corresponds to that of a highquality recording device. The proposed approach uses MFS and
LFS along with Mel Frequency Cepstral Coefficients (MFCC) and Constant-Q Cepstral Coefficients (CQCC) in a Decisionlevel Feature Switching (DLFS) paradigm to determine whether a given utterance is spoofed. The obtained results surpass the state-of-the-art Light Convolutional Neural Network (LCNN) based replay detection system with a relative improvement of 7.43\% on the ASV-spoof-2017 evaluation dataset.}
}

@INPROCEEDINGS{8724477, 
author={M. {Jain} and M. S. {Saranya} and H. A. {Murthy}}, 
booktitle={2018 International Conference on Signal Processing and Communications (SPCOM)}, 
title={An SVD Based Approach for Spoken Language Identification}, 
year={2018}, 
volume={}, 
number={}, 
pages={312-316}, 
keywords={Gaussian processes;learning (artificial intelligence);mixture models;singular value decomposition;speech processing;support vector machines;vectors;T-matrix;SVD;UBM-GMM;MAP adaptation;L singular vectors;SVM-based classifier;test supervector;reduced dimension test vector;SVM classifier;LID system;singular value decomposition based approach;proxy projection technique;TVS based framework;spoken language identification reduction;CallFriend dataset;Topcoder dataset;universal background model-Gaussian mixture model;time 30.0 s;TV;Training;Mathematical model;Hidden Markov models;Feature extraction;Testing;Support vector machines}, 
doi={10.1109/SPCOM.2018.8724477}, 
ISSN={2474-915X}, 
month={July}
}

@inproceedings{D2018,
  author={Vinothkumar D and Mari Ganesh Kumar and Abhishek Kumar and Hitesh Gupta and Saranya M. S and Mriganka Sur and Hema A. Murthy},
  title={Task-Independent EEG based Subject Identification using Auditory Stimulus},
  year={2018},
  booktitle={Proc. Workshop on Speech, Music and Mind 2018},
  pages={26-30},
  doi={10.21437/SMM.2018-6},
  url={http://dx.doi.org/10.21437/SMM.2018-6},
  abstract={Recent studies have shown that task-specific electroencephalography (EEG) can be used as a reliable biometric. This paper extends this study to task-independent EEG with auditory stimuli. Data collected from 40 subjects in response to various types of audio stimuli, using a 128 channel EEG system is presented to different classifiers, namely, k-nearest neighbor (k-NN), artificial neural network (ANN) and universal background model - Gaussian mixture model (UBM-GMM). It is observed that k-NN and ANN perform well when testing is performed intrasession, while UBM-GMM framework is more robust when testing is performed intersession. This can be attributed to the fact that the correspondence of the sensor locations across sessions is only approximate. It is also observed that EEG from parietal and temporal regions contain more subject information although the performance using all the 128 channel data is marginally better.}
}
